\documentclass[a4paper,11pt]{article}
\usepackage{fullpage}
\usepackage[english]{babel}
\usepackage{amsmath,amsfonts,amssymb,graphicx,amsthm}

\usepackage{cite}
\usepackage{xcolor}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}


\graphicspath{{./fig/}}
\newcommand{\eps}{\varepsilon}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\etal}{\emph{et al.}\xspace}
\newcommand{\?}{\mskip1.5mu}
\newcommand{\Patrascu}{P\v{a}tra\c{s}cu\xspace}
\def\..{\,\mathpunct{\ldotp\ldotp}} % Middle stuff for intervals. Usage: \..
\DeclareMathOperator{\lcp}{lcp} % longest common prefix
\DeclareMathOperator{\lca}{lca} % least common ancestor
\DeclareMathOperator{\exit}{exit}
\DeclareMathOperator{\lrange}{\ell}
\DeclareMathOperator{\rrange}{r}
\DeclareMathOperator{\extent}{extent}
\DeclareMathOperator{\Pref}{Pref}
\DeclareMathOperator{\pred}{pred}
\DeclareMathOperator{\fbs}{FBS}




\usepackage[ruled,noend,linesnumbered,algosection]{algorithm2e}
\newenvironment{alg}{
  \begin{algorithm}[htbp]
    \DontPrintSemicolon
    \SetKwInput{KwIn}{input}
    \SetKwInput{KwOut}{output}
  }{\end{algorithm}}

\newcommand{\aremark}[3]{\textcolor{blue}{\textsc{#1 #2:}}
  \textcolor{red}{\textsf{#3}}}
\newcommand{\djamal}[2][says]{\aremark{Djamal}{#1}{#2}}
\newcommand{\paolo}[2][says]{\aremark{Paolo}{#1}{#2}}
\newcommand{\marcel}[2][says]{\aremark{Marcel}{#1}{#2}}
\newcommand{\wolfgang}[2][says]{\aremark{Wolfgang}{#1}{#2}}


  

\title{TBD\footnote{
Preliminary versions appeared as 
D. Belazzougui, P. Boldi, and S. Vigna. 
\emph{Predecessor search with distance-sensitive query
time}. \texttt{arXiv:1209.5441}, 2012
and 
M. Ehrhardt and W. Mulzer.  \emph{Delta-Fast Tries: Local 
Searches in Bounded Universes with Linear Space}. Proc.~15th WADS,
2017.  WM was partially 
supported by DFG project MU/3501-1 and ERC StG 757609.}}

\author{Djamal Belazzougui\thanks{Universit\'e Paris 
        Diderot---Paris 7, France,
        \texttt{djamal.belazzougui@gmail.com}}
        \and
        Paolo Boldi\thanks{Universit\`a degli Studi di Milano, Italy, 
	\texttt{boldi@dsi.unimi.it}}
        \and
        Marcel Ehrhardt\thanks{Institut f\"ur Informatik, Freie 
	Universit\"at Berlin,
        \texttt{\{marehr, mulzer\}@inf.fu-berlin.de}}
        \and 
        Wolfgang Mulzer\footnotemark[4]
        \and 
        Sebastiano Vigna\thanks{Universit\`a 
	degli Studi di Milano, Italy, 
	\texttt{vigna@acm.org}}
        }
\date{}
%---------------------------------------------------------------------

\begin{document}
\maketitle

\begin{abstract}
\wolfgang{TODO}
\end{abstract}

\iffalse
\section{Sensitive Abstract}
A \emph{predecessor (successor) search} finds the largest 
element $x^-$ smaller than the input string $x$ (the smallest 
element $x^+$ larger than or equal to $x$, respectively) out of 
a given set $S$; in this paper, we consider the static case 
(i.e., $S$ is fixed and does not change over time) and assume 
that the $n$ elements of $S$ are available for inspection. We 
present a number of algorithms that, with a small additional 
index (usually of $O(n\log w)$ bits, where $w$ is the string 
length), can answer predecessor/successor queries quickly and 
with time bounds that depend on different kinds of \emph{distance},
improving significantly several results that appeared in the 
recent literature. Intuitively, our first result has a running 
time that depends on the distance between $x$ and $x^\pm$: 
it is especially efficient when the input $x$ is either very 
close to or very far from $x^-$ or $x^+$; our second result 
depends on some global notion of distance in the set $S$,
and is fast when the elements of $S$ are more or less equally 
spaced in the universe; finally, for our third result we rely 
on a \emph{finger} (i.e., an element of $S$) to improve upon 
the first one; its running time depends on the distance between 
the input and the finger.
\fi

\section{Introduction}

Predecessor searching is one of the oldest problems 
in theoretical computer science~\cite{CormenLeRiSt09,Knuth98}: 
let $U$ be a totally ordered universe. The task is 
to store a subset $S$ of $U$, while supporting 
\emph{predecessor} and \emph{successor} queries: 
given $q \in U$, find the largest element in $S$ 
smaller than $q$ (the predecessor of $q$) or the 
smallest element in $S$ larger than $q$ (the 
successor of $q$). In the \emph{dynamic} version, 
we also allow modification of $S$ by insertion 
and/or deletion of elements from $U$.

For the predecessor searching problem, the model 
of computation is of particular importance. In 
the \emph{word-RAM} model, all input elements 
are represented by $w$-bit \emph{words}, where 
$w \in \N$ is a parameter. Thus, we can assume 
that the universe is $U = \{0, \dots, 2^{w}-1\}$. 
Moreover, we assume that $w$ 
is a power of $2$. This does not lead to any 
loss of generality, since our asymptotic bounds 
are not affected when $w$ is changed by a factor of 
at most $2$. The word-RAM model allows us to 
manipulate the data words at the bit level, 
in constant time per operation. A classic 
method for predecessor searching on the 
word-RAM is due to van Emde Boas, who described 
a dynamic data structure that requires $O(n)$ words
of space and supports insertions, deletions, and 
predecessor queries in 
$O(\log w) = O(\log\log |U|)$ 
time~\cite{vEmdeBoas77,vEmdeBoasKaZi76,CormenLeRiSt09}.
Here, $n$ denotes the current size of the
(dynamically changing) set $S$. This data 
structure is now commonly known as the 
\emph{van-Emde-Boas tree}~\cite{CormenLeRiSt09}.

For the \emph{pointer-machine} model of computation, 
which is more restrictive than the word-RAM, it has 
been known for a long time that a variant of the 
van-Emde-Boas tree provides optimal 
performance~\cite{MehlhornNaAl88,Mulzer09}.
For the word-RAM, \Patrascu and Thorup~\cite{PatrascuTh06,PatrascuTh07} 
recently showed that structures similar to the 
van-Emde-Boas tree (e.g., $y$-fast tries~\cite{Willard83}) 
with query time $O(\log w)$ are optimal, assuming that 
we desire the space requirement to be linear in the 
size of $S$. More generally, the lower bound of 
\Patrascu and Thorup~\cite{PatrascuTh06,PatrascuTh07} 
encompasses several regimes, depending on the 
space that is available for the data structure.
For instance, another case is realized by exponential 
trees~\cite{AnderssonTh07}.\wolfgang{Which case is this?
Provide more details?} 
For a comprehensive discussion of the literature, we refer
the reader to \Patrascu's thesis~\cite{Patrascu08}.

Thus, it is fair to say that by now, 
the worst-case complexity of the predecessor 
searching problem has been settled. However, there is 
still room for improvement: first, suppose we are 
given the original set $S$ as a sorted array. Then,
we may desire a data structure that requires 
only \emph{sublinear} additional space and answers
predecessor queries for $S$ in optimal time; second, 
we may ask for a more nuanced guarantee on the query 
time that could depend on the structure of $S$ or on 
the relationship between the query element $q$ and 
the set $S$. More concretely, suppose our data 
structure currently contains the set $S \subseteq U$. 
To model the structure of $S$, we write $\Delta_M$ 
and $\Delta_m$ for the maximum and minimum distance 
between any two consecutive elements of $S$.
Furthermore, let $q \in U$ be the query element,  
and write
\[
  q^+ := \min\{s \in S \mid s \geq q \}
\]
and
\[
q^- := \max\{s \in S \mid s < q \}
\] 
for the 
successor and the predecessor of $q$ in $S$.
Then, we have several ways to model the
relationship between $S$ and $q$: 
let 
\[
d(q, S) = \min\big\{|q - q^-|, |q - q^+|\big\}
\]
and 
\[
D(q, S) = \max\big\{|q - q^-|, |q - q^+|\big\}.
\]
We call $d(q,S)$ the \emph{short distance} and 
$D(q, S)$ the \emph{long distance} between $q$ and 
$S$.
The short distance $d(q, S)$ is small when $q$ is 
close to an element of $S$, whereas $w - \log D(q, S)$
is small when $q$ is far from either $q^+$
or $q^-$. 

In 2013, Bose~\etal~\cite{BoseDoDuHoMo13} described
a word-RAM data structure for the dynamic predecessor
problem that is \emph{local} with respect to updates
and queries.
More precisely, their structure can answer predecessor 
and successor queries and perform updates 
in $O(\log\log d(q, S))$ time.
In a sense, this bound interpolates between
the $O(1)$ time of a hash table (for the
case that $q \in S$), and the $O(\log w)$ 
time of a van-Emde-Boas tree (if $q$ is far from
any element in $S$).
The structure of Bose~\etal~requires $O\big(n w \log\log w)$ bits 
of space, where $n = |S|$ is the size of the 
current set. Bose~\etal~apply their structure in 
the context of computational geometry; 
namely for approximate nearest 
neighbor queries in low dimensions and for 
dominance and range searching on a grid~\cite{BoseDoDuHoMo13}.
Here, we describe data structures for the
static and dynamic predecessor problem
on the-word RAM that provide significant 
improvements over previous bounds.\footnote{Our 
space bounds are always given as the
number of bits \emph{in addition} to those needed for 
representing $S$.} 

\begin{enumerate}
  \item We match the static worst-case search time 
  $O(\log\log d(q, S))$
  of Bose~\etal~\cite{BoseDoDuHoMo13}, but our index requires 
  just $O(n\log w)$ additional bits of space (and thus overall 
  linear space).
  \item Using $O(nw)$ bits, we can match the dynamic
  update and search time $O(\log\log d(q, S))$
  of Bose~\etal~\cite{BoseDoDuHoMo13}.
  \item 
  \wolfgang{Make reference more precise?}
  We improve exponentially over the \emph{interval-biased search
  trees} of Bille~\etal~\cite{BilleLaRaSaSaWe15}, answering 
  predecessor queries in time\footnote{Bille~\etal~\cite{BilleLaRaSaSaWe15} 
  state a bound of $O(w - \log(q^+ - q^-))$. Our 
  proofs work also work when replacing $D(q, S)$ with $q^+ - q^-$, but 
  the difference is immaterial, as $q^+ - q^-\leq 2D(q, S)$. We state
  our bound as above, since
  we find the duality with the previous bound more intuitive.} 
  $O(\log(w - \log D(q, S)))$, with 
  $O(n\log w)$ additional bits.
  \item We improve exponentially over the \emph{interpolation
  search} of Demaine~\etal~\cite{DemaineJoPa04}, answering
  predecessor queries in time 
  $O(\log\log(\Delta_M / \Delta_m))$, with
  $O(n\log w)$ additional bits.
  \item Finally, with slightly more (but still sublinear) space,
  we can exploit a \emph{finger} $r \in S$ to speed up our third 
  result to $O\left(\log(\log|q - r| - \log D(q, S))\right)$, which is in
  some cases better than the bound reported
  by Andersson and Thorup~\cite{AnderssonTh07}, and improves 
  exponentially over interval-biased search trees, which need 
  time  
  $O\left(\log(2^w - r) - \log D(q, S)\right)$~\cite{BilleLaRaSaSaWe15}.
  \wolfgang{Make reference more precise?}
\end{enumerate}
We remark that a combination of the first
and the third result shows that static predecessor 
search can be performed in time  
$O(\log \min \{\,\log d(x,S),w-\log D(x,S)\,\})$ 
with $O(n \log w)$ additional bits. 
\wolfgang{Expand on the next sentence? Say more about fat binary search?}
Our 
results are obtained by starting from a refined version of
\emph{fat binary search in a $z$-fast trie}~\cite{BelazzouguiBoPaVi09}.
The idea is that
he initial search interval can be specified under 
suitable conditions. This confirms the intuition that fat
binary search can be used as a very versatile building block 
for obtaining new data structures.

\section{Notation and Tools}
\label{sec:notation}

\paragraph{Basic Notation.}
We use $\log x$ to denote the binary logarithm, and we set 
$\log x := 1$, for $x \leq 2$.
We write $\eps$ for the empty string. For $k \in \N$, we denote by 
$\{0, 1\}^k$ the set of all binary strings of length $k$, by 
$\{0,1\}^+ := \bigcup_{k = 1}^{\infty} \{0, 1\}^k$ the set of all
nonempty finite binary strings, and by 
$\{0,1\}^* := \{0, 1\}^+ \cup \{\eps\}$ the set of all finite binary 
strings, including the empty string. 
The length of $q \in \{0, 1\}^*$ is denoted by $|q|$.
For a string $q \in \{0, 1\}^*$ and $a, b \in \N$ with $a \leq b$, 
we write $q[a, b]$ for the substring of $q$ starting at position
$a$ and ending at position $b$.  The indices start from $0$. 
We abbreviate $q[a, a]$ as $q[a]$. For two binary strings 
$q, r \in \{0,1\}^*$, we write $q \preceq r$ to indicate that $q$ is 
a prefix of $r$, and $q \prec r$ to indicate that $q$ is a proper 
prefix of $r$. 
Given a set $S \subseteq \{0, 1\}^*$, we write 
$\Pref(S) = \{p \in \{0, 1\}^* \mid \exists s \in S: p \preceq s\}$
for the set of all prefixes of the strings in $S$.
Given a string 
$q \in \{0,1\}^+$, we denote with $q + 1$ and $q - 1$ the strings in 
$\{0, 1\}^{|q|}$ that come before and after $q$ in lexicographic 
order. We use the convention that $0^k - 1 = 1^k + 1 = \bot$, for 
$k \in \N$, since then the predecessor of $0^k$ and the successor
of $1^k$ do not exist. 

\paragraph{The Word RAM.}
Let $w \in \N$ be a power of two. We work in the word RAM 
model with word-length $w$. This means that our data is given
as a linear sequence of $w$-bit words from $\{0, 1\}^w$, 
and that we can access each
data word in constant time, given its address. 
Certain operations involving two $w$-bit words
can be performed in constant time.
We allow any operation on two $w$-bit
words that lies in $\text{AC}_0$, the complexity class of
all Boolean functions that can be realized by a 
circuit of AND and OR gates with polynomial size, constant depth,
and unbounded fan-in~\cite{AroraBa09}.
This includes
bit-wise operations such as \texttt{and}, \texttt{or}, 
\texttt{not}, etc., arithmetic operations
such as \texttt{add}, \texttt{sub}, and
shifting operations such as \texttt{shl}, \texttt{shr}.
In addition, we make use of two more $\text{AC}_0$-operations that are 
implemented on most modern processors:
\texttt{msb} and \texttt{lsb} find the index of the
most significant and the least significant non-zero bit
in a given $w$-bit word.
The multiplication operation \texttt{mul} plays a special
role: it is not in $\text{AC}_0$~\cite{FurstSaSi84}, but it is often used
for efficient word RAM algorithms~\cite{FredmanWi93}.
\wolfgang{What does this mean for us?}

In our algorithms, we sometimes need to work with
bit strings from $\{0, 1\}^*$ that have fewer than $w$ bits. 
These are represented by
two $w$-bit words: the first word encodes the length of the string, 
and the second word contains the string itself, padded with leading
zero bits.

\paragraph{Predecessor and Successor Queries.}
We are given a set $S \subseteq \{0, 1\}^w$ of $n$ binary strings of 
length $w$. We consider $S$ to be ordered according to the 
lexicographic order, and for $q \in \{0, 1\}^w$, we set
\begin{align*}
     q^- &= \max \{r \in S \mid r < q\},  && 
        \text{(the \emph{predecessor} of $q$ in $S$), and} \\
     q^+ &= \min \{r \in S \mid r \geq q\?\} && 
       \text{(the \emph{successor} of $q$ in $S$)}.
\end{align*}
If the maximum or minimum does not exist, we set $q^- = \bot$ or 
$q^+ = \bot$.  A \emph{predecessor} or \emph{successor query} is
given by a string $q \in \{0, 1\}^w$, and the answer is $q^-$ or 
$q^+$. In fact, we shall focus exclusively on predecessor queries. 
This does not affect the generality of our results,
also because our algorithms actually return the \emph{rank} of the 
predecessor in $S$, and thus are in principle more informative 
than basic predecessor operations
(e.g., the successor can be immediately computed by incrementing 
the resulting index).

\paragraph{Hash Maps.}
\wolfgang{TO CHECK: Do we need the full-randomness assumption in 
Theorem 2.1? Check about multiplication?}
Our data structure makes extensive use of
hashing. In particular, we will maintain several
succinct hash tables that store additional
information for supporting fast queries, both
in the static and in the dynamic setting.
For the static case,
we need to be able to store a constant-time $r$-bit function on 
$n$ keys using $O(rn)$ bits \wolfgang{Do we need the more
precise form of $rn + cn + o(n)$? Is there a theoretical
reference for this?}; the 
function may return arbitrary values outside of its domain. 
Practical implementations of this are described
in~\cite{BelazzouguiBoPaVi11}, a theoretical
construction was presented by
Chazelle~\etal~\cite{ChazelleKiRuTa04}. Its
properties are summarized in the following theorem:

\begin{theorem}\label{thm:bloomier_filter}
For any $r \geq 1$, there exists a static dictionary that
stores a static set $X$ of $n$ entries with keys 
from $\{0, \dots, 2^w-1\}$ and with 
associated values of $r$ bits each.
The dictionary supports queries in $O(1)$ time,
using $O(nr)$ \emph{bits} of space. The look-ups for entries
from $X$ always return the correct result, the values
for keys outside $X$ may return arbitrary values.
\qed
\end{theorem}


For the dynamic case, we will use a hash table described
by Demaine~\etal~\cite{DemaineMePaPa06}, whose
properties are summarized in the following theorem:

\begin{theorem}\label{thm:succinct_retrieval_only_hashtable}
For any $r \geq 1$, there exists a dynamic dictionary that
stores a dynamic set $X$ oof entries 
with keys from $\{0, \dots, 2^w-1\}$ and with 
associated values of $r$ bits each.
The dictionary supports updates and queries in $O(1)$ time,
using $O(n \log(w - \log n) + nr)$ \emph{bits} of space.
The look-ups for entries
from $X$ always return the correct result, the values
for keys outside $X$ may return arbitrary values.
The asymptotic bounds for the space and the queries are
worst-case, the bounds for the updates hold with
high probability.\qed
\end{theorem}

\section{Z-fast Tries} 

\subsection{Compressed Tries}
Our data structure is based on \emph{compressed
tries}~\cite{CormenLeRiSt09,Knuth98}. 
Let $S \subseteq \{0, 1\}^w$. The \emph{trie} $T'$ for $S$ 
is a binary tree of height $w$. Each node $v \in T'$ corresponds
to a bit string $e_v \in \{0,1\}^*$, called the \emph{extent} of $v$. 
The root has extent $\eps$. For each inner node $v$, the left child 
$u$ of $v$  has $e_u = e_v0$, and the right child $w$ of $v$ has 
$e_w = e_v1$ (one of the two children may not exist). The extents of
the leaves in $T'$ correspond to the elements of $S$, and the extents of the 
inner nodes are prefixes for the elements in $S$; see 
Figure~\ref{fig:trie}.

\begin{figure}
  \centering
  \includegraphics{trie}
  \caption{A trie (left) and a compressed trie (right) for the set 
  000, 100, 110, 111. The nodes are annotated with their
  extents. The longest common prefix of 101 is  10. The 
  lca of 101 in the compressed trie
    is the node labeled 1.}
  \label{fig:trie}
\end{figure}

The \emph{compressed trie} $T$ for $S$ is obtained
from $T'$ by contracting into a single edge each maximal path in $T'$ that
has only nodes with exactly one child.
The root of $T$ corresponds to the highest node of $T'$ that has 
two children.  Every inner node in $T$ has exactly two children,
and $T$ has $n$ leaves. 
Consequently, $T$ has $O(n)$ nodes. 

Let $v$ be a nonroot-node in the compressed trie $T$,
and suppose that $u$ is the parent of $v$ in $T$. Then, 
the extent $e_v$ of $v$ has the form $e_v = e_ubc_v$, 
where $e_u \in \{0, 1\}^*$ is the extent of $u$, $b \in \{0,1\}$ is 
a bit that indicates whether $v$ is the left or the right child
of $u$, and $c_v \in \{0, 1\}^*$ is called the \emph{compressed
path} of $v$. Both $e_u$ and $c_v$ may be empty, but $e_u$
can be empty only if $u$ is the root of $T$. 
We call $n_v = e_ub$ the \emph{name} of $v$.
Next, let $v$ be the root of $T$.
In this case, we set the compressed path $c_v$
to $e_v$, where the extent $e_v$ of the root may
be empty.
Furthermore, we set $n_v = \eps$.

Let $v$ be any node of $T$.
We call the extent $e_v$ 
\emph{internal} if $v$ is an internal node of $T$.
The \emph{skip interval} of $v$ is defined as
$[1, |e_v|]$, if $v$ is the root, and $[|n_v|, |e_v|]$, otherwise.
Given a string $q \in \{0, 1\}^*$ with $|q| \leq w$, the 
\emph{exit node} of $q$, denoted as $\exit(q)$, is the unique node
$v$ in $T$ such that $n_v$ is a prefix of $q$ and either
$e_v = q$ or $e_v$ is not a prefix of $q$.
Figure~\ref{fig:ztrie} illustrates these definitions.

\begin{figure}[t]
\centering
\includegraphics[scale=.80]{zpred-1.mps}\qquad\raisebox{2cm}{\small
$T$~\begin{tabular}{c}
\fbox{\begin{tabular}{lcl}
0010 & $\to$ & $001001$\\
00100110 & $\to$ & $00100110100100$\\
\end{tabular}}\qquad
\end{tabular}
}
\caption{(above) A compressed trie, the 
related names, and the function $T$ of the associated 
z-fast trie. The skip interval for $\alpha$ is $[7, 14]$. 
Dashed lines show the end of the handles of internal nodes.}
\label{fig:ztrie}
\end{figure}

\subsection{Z-fast Tries and Fat Binary Search}

We recall some key definitions from~\cite{BelazzouguiBoPaVi09}:

\begin{definition}[2-fattest numbers and handles] 
\label{def:twofattest}
Let $a, b \in \N$, $a \leq b$. The \emph{2-fattest number} 
of the interval $[a, b]$ is the unique integer in $[a, b]$ 
that is divisible by the largest power of two. Equivalently, 
it is the integer with the largest number of trailing zeroes 
in its binary representation. The \emph{handle} $h_v$ of a 
node $v$ in a compressed trie is the prefix of $e_v$ whose 
length is the 2-fattest number of the skip interval of $v$
(see Figure~\ref{fig:ztrie}). If the skip interval of $v$ 
is empty (which can happen only at the root), we set 
$h_v = \eps$.
\end{definition}

We remark that if $c$ is the 2-fattest number of $[a, b]$, then 
$c$ is also the 2-fattest number in every subinterval of $[a, b]$ 
that contains it.

\begin{definition}[z-fast trie]
Suppose we are given a set $S \subseteq \{0, 1\}^w$. Let $T$ be the 
compressed trie for $S$. The \emph{z-fast trie on $S$} is 
a function $Z : \{0, 1\}^* \rightarrow \{0, 1\}^*$ such that 
$Z(h_v) = e_v$, for every internal node $v$ of $T$, and such
that any other string is mapped to an arbitrary internal extent
of $T$.\footnote{Recall that the inputs and outputs of $Z$
are represented as two $w$-bit words, encoding the length
and the padded string.}
\end{definition}

Given a z-fast trie $Z$ for $S$, we can determine very 
quickly the name of the exit node for any query string $q \in \{0,1\}^+$.
For this, we use a variant of binary search, called 
\emph{fat binary search}.
The goal is to find the length $|e|$ of the 
longest internal extent $e$ that is a proper 
prefix of $q$. Once $|e|$ is known, the name 
of $\exit(q)$ is obtained as $q\big[0, |e|\big]$.
The fat binary search is started with an initial
search interval $[a,b]$ that is guaranteed
to contain $|e|$. The main difference to
a standard binary search is that we do
not split the search interval on its
midpoint, but on its 2-fattest number.
Furthermore, we maintain the invariant
that the left endpoint of the search interval $a$ 
is the length of an internal extent
of $T$.  This makes the search order more
predictable: all the decision points of the
fat binary search are contained in the z-fast trie
and are readily available after preprocessing.
See the pseudo-code in Algorithm~\ref{algo:query} for details. 
The algorithm reported here, an extension of the 
result from~\cite{BelazzouguiBoVi10}, has two main features:
it imposes very weak requirements on $Z$, and it allows us to start 
the search on a small interval that is subject to
mild conditions. This latter feature will be crucial 
for our main results. The next lemma formally states
the invariant of the fat binary search.

\begin{algorithm}
\KwIn{a string $q \in \{0,1\}^+$, an initial 
search interval $[a,b]$ so that  $a \in [0, |q|]$
and $a = 0$ or $q[0, a - 1]$ is an internal extent of $T$, and
so that $b \in [a, |q|]$ and $b$ is larger than the length 
of the longest internal extent of $T$ that is a proper prefix of $q$}
\KwOut{the name of $\exit(q)$}
\While{$b - a > 1$}{%
$c \gets $ the 2-fattest number in $[a + 1, b - 1]$%
\label{line:2fattest}\;
$e \gets Z(q[0, c - 1])$%
\label{line:qprefix}
\;
\If{$c \leq |e| \wedge e \prec q$
\label{line:prefixtest}
}{%
  \tcp{Move from $[a, b]$ to $[|e|,b]$}
 $a\gets |e|$\;
\label{alg1:reass1} 
} \Else{%
\tcp{Move from $[a, b]$ to $[a, c]$}
$b \gets c$\;
\label{alg1:reass2} 
}
}
\If{$a = 0 \wedge e_\text{root}\neq\eps$}{% 
  \Return $\eps$\;
} \Else{%
  \Return $q[0, a]$\;
}
\caption{Fat binary search in order to 
  determine the name of $\exit(q)$.}
\label{algo:query}
\end{algorithm}

\begin{lemma}\label{lem:correctness}
Let $q \in \{0, 1\}^+$ be a query string.
Let $e_0 = \eps$ and $e_1, e_2, \dots, e_t$ be the internal 
extents of $T$ that are \emph{proper} prefixes of $q$, ordered by 
increasing length.  Let $[a, b]$ be the search interval maintained by 
Algorithm~\ref{algo:query}. Before and after each iteration, the 
following invariants are satisfied: 
\begin{enumerate}
    \item\label{enu:lema} $a = |e_j|$, for some $j$;
    \item\label{enu:lemb} $b > |e_t|$.
\end{enumerate}
It follows that when the algorithm terminates, we have, $a = |e_t|$.
\end{lemma}

\begin{proof}
Consider invariant (\ref{enu:lema}).
At the beginning, the invariant holds
by our assumption on the initial search interval. 
Moreover, the invariant is maintained throughout
the algorithm. Indeed, the value of
$a$ changes only in line~\ref{alg1:reass1} of Algorithm~\ref{algo:query}. 
Suppose that currently we have $a = |e_j|$, for some $j$, and
that line~\ref{alg1:reass1} is executed. Then, we know that $e$ is an 
internal extent, that $|e_j| = a  < c  \leq |e|$, 
and that $e \prec q$. Thus, it follows that $e = e_k$, 
for some $k > j$.

Next, consider invariant (\ref{enu:lemb}).
At the beginning, the invariant holds 
by our assumption on the initial search interval.
To show that the invariant is preserved,
note that $b$ changes only in 
line~\ref{alg1:reass2}.
By invariant (\ref{enu:lema}), at the beginning of
an iteration of the \textbf{while}-loop, we have $a = |e_j|$, 
for some $j$.  
Let $v_{j+1}, \dots, v_{t}$ be the inner nodes in $T$ 
with $e_{v_k} = e_k$, for $k = j + 1, \dots, t$.
Then, the skip intervals of $v_{j+1}, \dots, v_t$ are 
pairwise disjoint, and their union is $[a + 1, |e_t|]$.
Thus, if $c \leq |e_t|$, then $c$ lies in the
skip interval of some $v_k$.
Since $c$ is 2-fattest in $[a + 1, b - 1]$, 
it is also 2-fattest in the skip interval of $v_k$. 
Hence, we have $q[0, c - 1] = h_{v_k}$ and 
$Z(q[0, c - 1]) = e_k$, 
which satisfies $c \leq |e_k|$ and $e_k  \prec q$. 
Thus, line~\ref{alg1:reass2} is executed only if $c > |e_t|$.
The invariant $b > |e_t|$ is preserved.
\end{proof}

We can now show that our fat binary search is correct.
\begin{theorem}
\label{thm:correctnessfbs}
Algorithm~\ref{algo:query} takes at most $\lceil\log(b-a)\rceil$
iterations
and finds the name of $\exit(q)$.
\end{theorem}

\begin{proof}
We first bound the number of iterations. Consider
an interval $[\ell, r]$ and suppose that
$[\ell, r]$ contains at most one multiple
of $2^i$. Furthermore, let $c$ be the 
$2$-fattest number in $[\ell, r]$.
Then, the two subintervals $[\ell, c - 1]$ and 
$[c + 1, r]$ each contain at most one multiple 
of $2^{i-1}$. Indeed, if one subinterval 
contained two such multiples, it would also 
contain a multiple of $2^i$ in its interior. 
However, this mutiple would have to be $c$, 
since $[\ell, r]$ contains no other multiple 
of $2^i$, a contradiction. It now follows 
by induction that after splitting the 
interval $[\ell, r]$ at most $i$ times, the 
resulting interval has length at most one. 
Now, since an interval of length $k$ contains at most one multiple of 
$2^{\lceil\log k\rceil}$, the algorithm
has at most $\lceil\log(b-a)\rceil$ iterations.

It remains to argue correctness. 
By Lemma~\ref{lem:correctness}, we know
that if the algorithm terminates, then
$a = |e|$, where $e$ is the longest internal
extent of $T$ that is a proper prefix of $q$,
or $a = 0$, if no such internal extent exists. If $a > 0$ 
then $q[0, a]$ is the name of $\exit(q)$.
If $a = 0$, there may be two 
reasons for this: (a) there is no internal
extent that is a proper prefix of $q$. In this case,
the extent of the root must be non-empty, and
$\exit(q)$ is the root; or (b) the longest internal
extent that is a proper prefix of $q$ is $\eps$.
In this case, this extent is located at the root, and 
$\exit(q)$ is the child of the root
that corresponds to the first bit
of $q$.
All these cases are handled by the
final case distinction in Algorithm~\ref{algo:query}.
\end{proof}

We comment on some implementation aspects of 
Algorithm~\ref{algo:query}.
First, in line~\ref{line:2fattest}, the 2-fattest
number in the interval $[\ell, r]$ with $\ell \leq r$
can be found in constant time with the expression 
\[
(1^w \texttt{ shl } 
\texttt{msb}((\ell - 1) \texttt{ xor } r)) \texttt{ and } r,
\]
where $1^w$ represents the $w$-bit word in which all bits
are set to $1$. Indeed, the 2-fattest number in $[\ell,r]$
is the number n $[\ell, r]$ with the maximum number of trailing zeroes
in its binary representation. To find this number, we identify
the index of the highest valued bit that changes from $0$ to
$1$ when counting from $\ell - 1$ to $r$, (this is
given by $\texttt{msb}((\ell - 1) \texttt{ xor } r))$), and 
we use an appropriate mask to find the corresponding
prefix of $r$. \wolfgang{Make a picture.}
Second, in line~\ref{line:qprefix}, the substring $q[0, c-1]$ 
can also be found in constant
time, using bit shifting to create an appropriate bit mask.
The same holds for the prefix test $e \prec q$ in line~\ref{line:prefixtest}.


\subsection{Implementing the Function $Z$}

We now explain the implementation details of the
z-fast trie $Z$. We split the computation of $Z$ into
two basic components:
\begin{enumerate}
  \item the \emph{handle resolver} $g: \{0,1\}^* \rightarrow \N$ 
    maps each handle $h_v$ of $T$ to the length of the name 
    $n_v$ of its associated 
    node $v$. That is, $g(h_v) = |n_v|$, for every internal node $v$ 
    of $T$. The value $g(h)$ is arbitrary of $h$ is not a handle of $T$;
  \item the \emph{range locator} receives a string $n \in \{0, 1\}^*$.
  If $n = n_v$  is the name of a node $v$ of $T$, it returns the minimum and
  maximum element of $S$ stored in the subtree of $T$
  rooted at $v$, i.e., the smallest element $s_{\lrange(v)}$ and the 
  largest element $s_{\rrange(v)}$ of $S$ that
  have $n_v$ as a prefix. If $n$ is not a valid name in $T$, the range
  locator returns two arbitrary elements $s_\ell$ and $s_r$ from $S$.
\end{enumerate}

These two data structures let us implement several efficient operations
on $T$. In particular, as was also observed by 
\Patrascu~\cite{Patrascu10}, the additional indirection
given by the handle resolver will lead to a space efficient implementation
of the z-fast trie $Z$.
Let $n_v \in \{0, 1\}^*$ be the name of a node $v \in T$. We 
write $\extent(n_v)$ for the extent $e_v$ of $v$. With the range locator,
we can implement the function $\extent(\cdot)$ with constant overhead.

\begin{lemma}\label{lem:getextent}
Suppose that a range locator for $T$ is available. 
Then, the following operation can be implemented
with one call to the range locator and $O(1)$
additional steps.
Given a string $n \in \{0, 1\}^*$: 
if $n$ is the name for a node in $T$, return
$\extent(n)$; if $n$ is not a valid name
in $T$, return an arbitrary valid extent in $T$.
\end{lemma}

\begin{proof}
Given $n$, we use the range locator to find 
two elements $s_\ell$ and $s_r$ in $S$.
If $s_\ell = s_r$, we return $s_\ell$.
Otherwise, we return the longest common prefix of 
$s_\ell$ and $s_r$. This can be done in
$O(1)$ steps, using the \texttt{msb}-operation
and appropriate bit-manipulation.
The procedure certainly returns a valid extent
in $T$, and if $n$ is the actual name of node
$v$ in $T$, then the result is $\extent(n)$, 
as desired.
\end{proof}

Combining Lemma~\ref{lem:getextent} with a handle resolver,
we can implement the z-fast trie efficiently.

\begin{lemma}\label{lem:implementz}
Suppose that a handle resolver and a range locator for $T$ are 
available. Then, 
we can implement the following operation with one call to the
handle resolver, one call to the range locator, and $O(1)$
additional operations:
for any given given string $h \in \{0, 1\}^*$,
if $h$ is a handle for a node in $T$, compute
$Z(h) = \extent(h)$; 
if $h$ is not a valid handle in $T$, return
any valid extent in $T$.
\end{lemma}

\begin{proof}
We use the handle resolver to find the presumptive length
$a$ of the name corresponding to $h$.
We set $n = h[0, a - 1]$,  
and  we use Lemma~\ref{lem:getextent}
to obtain an extent for $n$.
If $h$ is a valid handle, we obtain the required information by
Lemma~\ref{lem:getextent} and by the correctness of the handle 
resolver. If $h$ is not a valid handle, 
Lemma~\ref{lem:getextent} still yields a valid extent in $T$.
\end{proof}

Now, by Theorem~\ref{thm:succinct_retrieval_only_hashtable},
we can implement a handle resolver with constant 
query time, and with $O(n \log w)$ bits of 
space.  Furthermore, if $S = \langle s_1, s_2, \dots, s_n\rangle$ 
is given in lexicographic sorted order and can be accessed in
constant time \wolfgang{What does this mean? Random access to 
a table storing $S$?},
there is a constant-time range locator for $S$ using $O(n\log w)$
bits~\cite{BelazzouguiBoPaVi09}.
\wolfgang{Specific theorem? Put into intro}
This leads to the following theorem.

\begin{theorem}
\label{th:zfast}
Let $S \subseteq \{0, 1\}^w$.
If $S$ is given in lexicographic order and if constant time
access to $S$ is available, the z-fast trie $Z$ for $S$ can be
implemented in $O(1)$ with additional $O(n\log w)$ bits of space.
\qed
\end{theorem}

\subsection{From Exit Nodes to Predecessors}

Now consider a query string $q \in \{0, 1\}^w$.
By our discussion so far, we know that
with fat binary search, we can quickly find the 
(length of) the name of the exit node of $q$, $\exit(q)$. 
Now, we explain how we can use this
information to find $q^-$, the predecessor of $q$ in $S$.
Given $q$ and the length $t$ of the name of $\exit(q)$, 
we denote by  $\pred(q, t)$ the index of $q^-$
in the sorted array $S$.

\begin{lemma}
Suppose that a range locator for $T$ is available.
Let $q \in \{0, 1\}^w$ be a query string and
$t$ the length of the name of $\exit(q)$.
Then, we can compute $\pred(q, t)$ with one 
call to the range locator and with $O(1)$ additional
steps.
\end{lemma}
\begin{proof}
Since the name of $\exit(q)$ is given by $q[0, t - 1]$,
we can use Lemma~\ref{lem:getextent} to compute
the extent $\extent(q[0, t - 1])$ of $\exit(q)$.
This needs one call to the range locator and $O(1)$ 
additional steps.
Then, we check if $q \preceq \extent(q[0, t - 1])$ or 
if the first bit of 
$q$ at which $q$ and $\extent(q[0, t-1])$ differ is a $0$. 
This can be done in constant time, using the \texttt{msb}-function
and appropriate bit-shifting operations..
If so, the index of $q^-$ is $\lrange(\exit(q))-1$.
Otherwise, the index of $q^-$ is 
    $\rrange(\exit(q))$.
\end{proof}

We denote with $\fbs^-(q,a,b)$ the predecessor index computed by 
running Algorithm~\ref{algo:query} (with inputs $q$, $a$, and $b$) 
to obtain the name of $\exit(q)$ and then invoking $\pred(q, t)$.
We remark that the definition above implies that 
by evaluating $\fbs^-(q,0,|q|)$, we can find
the predecessor $q^-$ of a given query string $q$ 
in $O(\log w)$ time, using 
$O(n\log w)$ bits in addition to the sorted array $S$.

\subsection{Using the Range Locator to Check Prefixes}

Let $P \subseteq \Pref(S)$ be a set of prefixes of $S$, and
assume that we have a function $f : P \rightarrow \N$ that 
returns for each $p \in P$ the length of the name of 
$\exit(p)$.
Given a candidate prefix $p \in \{0, 1\}^*$, we would like 
to distinguish whether $p$ belongs 
to $P$ or is not a prefix of any string in $S$.\footnote{Note
that we make no claim for the case that $p$ belongs to
$\Pref(S) \setminus P$.}
Our key observation is that a range locator, combined with access 
to the sorted array $S$, can be used to extend 
$f$ so that it returns a special value $\bot$ outside of $\Pref(S)$:

\begin{theorem}
\label{th:pref}
Let $P \subseteq\Pref(S)$, and let $f: P \rightarrow \N$ be 
given by $f(p) = |n_{\exit(p)}|$, for $p \in P$.
Suppose that $f$ can be computed in constant time,
and that we have access to the sorted
array $S$ and to a range-locator for $S$ that
requires constant time.
Then, we can extend 
$f$ to a constant-time function $\widehat{f}: \{0, 1\}^* \rightarrow \N
\cup \{ \bot \}$ such that $\widehat{f}(p)=|n_{\exit(p)}|$, for 
all $p \in P$, and $\widehat{f}(p) = \bot$, for
all $p \not\in\Pref(S)$.
\end{theorem}

\begin{proof}
Given $p \in \{0, 1\}^*$, we invoke
$f$ to compute a candidate length $t = f(p)$ 
for $n_{\exit(p)}$.
If $t > |p|$, we return $\bot$.
Otherwise,  we use the presumptive
name $p[0, t - 1]$ of $\exit(p)$ 
in Lemma~\ref{lem:getextent} to compute 
the extent $e$ of $\exit(p)$. Now, 
if $p  \preceq e$, we return $f(p)$, otherwise we return $\bot$.

If $p\in P$, then $f(p) = |n_{\exit(p)}| \leq |p|$, and we
compute correctly the extent of $\exit(p)$, so we return 
$f(p)=|n_{\exit(p)}|$.
If $p \not\in \Pref(S)$, then the test if 
$p \preceq e$ must fail for every extent in $T$. 
Hence, in this case, last step returns $\bot$.\footnote{Observe 
that actually $\widehat f$ will return the length 
of the name of the exit node for all prefixes in a set $\hat P$ that 
satisfies $P\subseteq \hat P\subseteq\Pref(S)$.}
\end{proof}

\section{Locally Sensitive Predecessor Search}
\label{sec:pred}

We combine Theorems~\ref{th:zfast} and~\ref{th:pref} 
to answer predecessor queries in a time that depends 
on the distance between the query string $q$ and its 
predecessor and successor in $S$. The idea 
is to store selected prefixes from $\Pref(S)$
to reduce significantly the initial search interval of
Algorithm~\ref{algo:query} (by increasing the parameter $a$).
We devise two distinct predecessor algorithms whose 
performance depends on the short and on the
long distance between the $q$ and $S$:
both algorithms use the setup from Theorem~\ref{th:pref}, but with 
different choices of the function $f:P\to \N$. 

\subsection{Short-distance predecessor algorithm}

We use techniques inspired by the work of Bose 
et al.~\cite{BoseDoDuHoMo13} to obtain a
query time that depends on the short distance $d(q, S)$ 
between the query $q$ and $S$. For this, we
consider a sparse set $P$ of prefixes from which
we can start the fat binary search.
It is defined as follows:
\[
	P=\bigl\{\,s\bigl[0,w-2^{2^i} - 1\bigr] \mid s \in  S \text{ and }
	i=0,\dots,\lfloor\log(\log w - 1)\rfloor\,\bigr\}.
\]
To store the function $f: P\to \N$ used in Theorem~\ref{th:pref}, 
we define a subset of $P$:
\[
Q=\bigcup_{\text{node $v$ of $T$}}
\min{}_\preceq\{\,p\in P\mid n_v \preceq p\preceq e_v\,\}
\]
For every node $v$ of $T$, the set $Q$ contains
the shortest string in $P$ that sits between the name and the extent
of $v$ (if any). 
By Theorem~\ref{thm:succinct_retrieval_only_hashtable},
we can store a dictionary that maps every element 
$q \in Q$ to $|n_{\exit(q)}|$ in space $O(n \log w)$ as $|Q|\leq n$.
Furthermore, by Theorem~\ref{thm:bloomier_filter},
we can store another dictionary that maps
every $p\in P$ to the smallest index $i$ such that 
$p[0,w-2^{2^i} - 1]\in Q$.
Since $|P| = O(n \log\log w)$,
this map takes $O(n\log\log w\log\log\log w) = O(n\log w)$ bits. 
To compute $f(p)$, we first find the index $i$ for $p$ in 
the second map, and then we query the first map with 
$p\bigl[0, w - 2^{2^i} -1\bigr]$. 

Now, our strategy is to 
evaluate the function $f$ 
with prefixes of the query string $q$ 
of decreasing lengths.
More precisely, at iteration $i$, we evaluate
$f(p)$ with the prefix $p$ of $q$ with 
length $t = w-2^{2^i}$. 
If this succeeds, we have found a valid prefix of $q$ in $T$,
and we can proceed with the fat binary search.
If not, we evaluate for 
$f(p+1)$ and for $f(p-1)$. If this succeeds, it is
easy to find $q^-$ with the range locator.
If none of our tests succeeds, we proceed to the next
iteration $i+1$. See Algorithm~\ref{algo:pred-short} 
for the details.
\begin{algorithm}
\KwIn{a query string $q\in \{0, 1\}^w$}
\KwOut{the index $j$ such that $S[j] = q^-$}
 $i \gets 0$\;
\While{$2^{2^i} \leq w/2$}{%
  $p \gets q\bigl[0, w-2^{2^i} - 1\bigr]$\;
  $t \leftarrow \widehat{f}(p)$\;
  \If{$t \neq \bot$ }{%
       $e \gets \extent(q[0,t-1])$\;
       \If{$e\prec q$}{%
           \tcp{We found a long extent}
           \Return{$\fbs^-(q,|e|,|q|)$}\;
	   \label{line:ret1}
       }
       \tcp{We exit at the node of name $q[0, t-1]$}
       \Return{$\pred(q,t)$} 
       \label{line:ret2}
  }
  $t \gets \widehat{f}(p+1)$\;
  \If{$t \neq \bot$}{%
    \tcp{$q^-$ is the predecessor of $p+1$} 
    \Return $\lrange((p+1)[0,t-1])-1$ 
    \label{line:ret3}
  }
  $t \leftarrow \widehat{f}(p-1)$\;
  \If{$t \neq \bot$}{%
    \tcp{$q^-$ is the successor of $p-1$} 
    \Return $\rrange((p-1)[0,t-1])$  
  }
  $i \gets i + 1$
}
\tcp{Standard search (we found no prefix long enough)}
\Return{$\fbs^-(q,0,|q|)$}
\caption{Short-distance speedup.}
\label{algo:pred-short}
\end{algorithm}

The following lemma helps us bound the number of
iterations of Algorithm~\ref{algo:pred-short}.
\begin{lemma}
\label{lemma:hitpref}
Let $q \in \{0, 1\}^w$ be a query string.
Let $j \in \N$ with $j \leq w-\log d(q,S)$ be given, 
and set $p=q[0,j - 1]$. 
Then, at least one of $p$, $p+1$, or $p-1$ 
belongs to $\Pref(S)$. 
\end{lemma}

\begin{proof}
There are $2^{w-j}$ strings in $\{0, 1\}^w$
with prefix $p$ ($q$ being one of them), and the same holds
for $p - 1$ and $p + 1$. 
Let $s$ be the string in $S$ that realizes
$d(q, S)$, i.e., $s = q^-$ or $ s = q^+$.
Then, by our assumption on $j$, we have $|q-s| \leq 2^{w-j}$, 
so $s$ must have prefix either $p$ or $p + 1$ or $p-1$.
\end{proof}


\begin{theorem}
Algorithm~\ref{algo:pred-short} returns the predecessor of $q$
in time $O(\log\log d(q,S))$, using an index with 
$O(n \log w)$ bits of space (in addition to the space 
to store the elements of $S$).
\end{theorem}

\begin{proof}
First, we show correctness. If we reach the first return
instruction in Line~\ref{line:ret1}, then $e$ is a valid 
extent and a prefix of $q$, so we start correctly a
fat binary search. At the second return instruction
in Line~\ref{line:ret2}, we know the $q[0, t - 1]$ is
the name of a node $v$, but the extent of 
$v$ is not a prefix of $q$, so
$q$ exits exactly at $v$, and again we return the correct answer. 
If $p + 1$ is a valid prefix of some element of $S$, but $p$ is not, 
then the predecessor
of $p$ is the predecessor of the least element prefixed by $p + 1$, which we
return in Line~\ref{line:ret3} (and analogously for $p - 1$).

Next, we argue about the running time.
By Lemma~\ref{lemma:hitpref}, we will hit a prefix in our set $P$ as soon as
$w - 2^{2^i} \leq w - \log d(q,S)$, that is, as soon as 
$i > \log\log\log d(q, S)$. If $i$ is the
smallest integer satisfying the latter condition, then 
$i - 1 \leq \log\log\log d(q, S)$, so $2^{2^i} \leq (\log d(q, S))^2$, 
which guarantees that the fat binary
search, which starts from an extent of length at least $|e| \geq t \geq
w - 2^{2^i} \geq w - (\log d(q, S))^2$, will complete in time 
$O(\log b - a)=O(\log\log d(q, S))$ (see Theorem~\ref{thm:correctnessfbs}). 
If we exit from the loop,
it means that $i > \log\log\log d(q, S)$ which implies $2^{2^i}>w/2$, hence
$(\log d(q,S))^2>w/2$, so the last fat binary search  taking $O(\log w)$
steps to complete) is still within our time bounds.
\end{proof}

\subsection{Long-distance predecessor algorithm}
\label{sec:long}

We now discuss Algorithm~\ref{algo:pred-long}, whose 
running time depends on long
distances. Let $P$ be the set obtained by ``cutting''
every internal extent $e_v$ to the length of the smallest power of 
$2$ (if any) in the skip interval of $v$, that is:
\[
P =\bigcup_\text{$v$ internal}\{\,e_v[0,2^k -1] \mid 2^k \in
	[|n_v|, |e_v] \text{ and $k$ is the smallest possible}\,\}.
\]
where $v$ ranges over all nodes. This time, we
have at most one prefix per node, so $|P| = O(n)$, and 
the function $f$ required by Theorem~\ref{th:pref} can be stored 
in $O(n\log w)$ bits, by Theorem~\ref{thm:succinct_retrieval_only_hashtable}. 

Algorithm~\ref{algo:pred-long} keeps track of the length $a$ of an
internal extent that is known to be a prefix of $q$. At each step, we 
try to find another extent by probing a prefix of $q$ whose 
length is the smallest power of $2$ larger than
$a$. By the construction of $P$, we can miss the longest
prefix length at most by a factor of two. 

\begin{lemma}
\label{lemma:shortinprefs}
Let $q \in \{0, 1\}^w$ be a query string,
and let $p \in \Pref(S)$ with 
$|p| > w - \log D(q,S)$ and
$p \preceq q$. Then, 
the elements in $S$ with prefix $p$
are either all at most as large or all
at least as large as $q$.
\end{lemma}

\begin{proof}
Since $|p| > w - \log D(q, S)$, we have
that $p$ is a prefix of less than
$2^{\log D(q,S)} = D(q, S)$ strings.
From the definition of $D(q, S)$ it follows
that $|q^+ - q^-| \geq D(q, S)$, so $p$
cannot be a prefix of both $q^+$ and $q^-$.
Now, since the set of strings in $S$ 
with prefix $p$ forms an interval, all elements
in $S$ with prefix $q$ are either all at most as large
or all at least as large as $q$.
\end{proof}


\begin{theorem}	
\label{thm:pred-long}
Algorithm~\ref{algo:pred-long} returns the predecessor of  $q$
in time $O(\log(w-\log D(q, S)))$, using an index with 
$O(n \log w)$ bits of space (in addition to the space 
to store the elements of $S$).
\end{theorem}

\begin{proof}
First, we show correctness. An easy induction shows that throughout
the algorithm, $a$ is either $0$ or the length of an 
internal extent that is a prefix of $q$. 
Then, it follows that since $[a + 1,w - 1]$ is a union of 
consecutive skip intervals and since
the smallest power of $2$ in interval $[a + 1,w - 1]$ is
a fortiori the smallest power of two in a skip interval of $T$,
that of $q[0, m-1]$ is in $\Pref(S)$, then $q[0, m-1]$ must be in $P$.
Thus, if $t = \bot$, Theorem~\ref{th:pref} implies that $m$
must be larger than the length of the longest internal extent
that is a proper prefix of $q$, 
so if we exit at the first return
instruction in Line~\ref{line:retb1}, 
the fat binary search completes correctly. On the other hand, 
if $t \neq \bot$,
we know that $q[0,t - 1]$ is the name of a node $v$ in $T$.
If  
$q$ is smaller than the smallest leaf
under $v$ (or larger than the largest such under $v$),
we immediately know the
predecessor and can safely return with a correct value
in line~\ref{line:retb2} or~\ref{line:retb3}. The return instruction
after the loop in line~\ref{line:retb4} is trivially correct.

Next, we discuss the running time. Observe that when $m > w - \log D(q, S)$,
then either the string $q[0,m -1]$ will not be in 
$\Pref(S)$ (by Lemma~\ref{lemma:shortinprefs}) and thus 
$t=\bot$, or $q$ will be larger (or
smaller) than every element of $S$ prefixed by $q[0,t-1]$, 
which will cause a loop exit at one of the last two \textbf{if}-instructions. 
Since $m$ gets at
least doubled at each iteration, this will happen 
after at most $\log(w-\log D(q,S))$ iterations; moreover, 
$m \leq 2a$ (because there is always a power of $2$ in the interval 
$[a + 1, 2a]$), so the fat binary search in line~\ref{line:retb1}
will take no more than $\log(m-a)\leq \log a\leq \log (w-\log D(q,S))$ steps.
If the loop exits naturally, then there is a prefix of $q$ belonging to 
$\Pref(S)$ and longer than $w/2$, hence $w-\log D(q, S)\geq w/2$ and 
the fat binary
search at the end of the loop will end within the prescribed time bounds.
\end{proof}

\begin{algorithm}
\KwIn{a query string $q \in \{0, 1\}^w$}
\KwOut{the index $i$ such that $S[i]=q^-$}

 $a \gets 0$\;
\While{$a<w/2$}{%
  $m \gets \text{least power of $2$ in $[a+1,w-1]$}$\;
  $t \gets \widehat f(q[0, m-1])$\;
  \If{$t = \bot$}{%
     \Return{$\fbs^-(q,a,m)$}
     \label{line:retb1}
     \tcp{We obtained the longest possible prefix} 
  }
  $p \gets q[0,t-1]$\;
  \If{$S[\lrange(p)]\geq q$}{%
    \Return{$\lrange(p)-1$}
    \label{line:retb2}
  }
  \If{$S[\rrange(p)]<q$}{%
    \Return $\rrange(p)$
    \label{line:retb3}
  }
  $a \gets |\extent(p)|$ 
  \tcp{This is a valid extent}
}
\Return{$\fbs^-(q, a, w)$}
\label{line:retb4}

\caption{Long-distance speedup.}
\label{algo:pred-long}
\end{algorithm}

Finally, we can combine our improvements for short and long 
distances, obtaining an algorithm that is
efficient when the query $q$ is either very close to or very far 
from $q^-$ or $q^+$:

\begin{corollary}
It is possible to compute the predecessor of a query $q$ in a set $S$
of $n$ elements in time $O(\log \min \{\,\log d(q, S), w - \log D(q,S)\,\})$, 
using an index that
requires $O(n \log w)$ bits of space (in addition to the space
needed to store the elements of $S$).
\end{corollary}

\subsection{Dynamic Version}

We will now explain how to make our data
structure dynamic. 
The basic approach remains the same.
However, in contrast to the static case, we now 
maintain the compressed trie $T$ explicitly. 
This means that we do not assume that $S$
is given in a static read-only array with constant
time access, but that the elements of $S$
are stored in a trie that changes dynamically throughout
the algorithm. In particular, our space bounds must also 
include the bits to represent $S$, so the best 
that we can hope for is a data structure that uses $O(nw)$
bits, where $n$ is the current size of $S$. This less restrictive
space regime simplifies some aspects of the algorithm. For example,
the z-fast trie for $S$ can now be maintained explicitly in a
dynamic dictionary. The greatest challenge now is to maintain
the dynamic trie $T$ under the required time bounds and to provide
a fast way to go from the exit node of a given query string $q$ to the 
predecessor of $q$.

In more detail, the compressed trie $T$ is maintained as
an explicit pointer structure with parent and
child pointers. The leaves of $T$ are
linked in sorted order. For each node
$v$ of $T$, we store the extent $e_v$,
so given a node $v$ and the pointer structure
of $T$, we can easily derive all the associated
information for $v$ in constant time, i.e., the extent $e_v$, 
the name $n_v$, the compressed path $c_v$, the handle $h_v$, and the skip 
interval for $v$.
Furthermore, we need a structure similar to the range locator 
that is given a node $v$ of $T$ and provides pointers to
the largest and the smallest element of $S$ in the subtree
$T_v$ of $T$ that is rooted at $v$. This structure is more non-trivial
to handle dynamically in the desired time bounds, and we will elaborate
on this below. Finally, the z-fast trie is stored as an explicit
dynamic dictionary as in Theorem~\ref{thm:succinct_retrieval_only_hashtable}.

\subsubsection{Locating the Exit Node for a Query String}

Since our dynamic algorithm must be able to update the
compressed trie explicitly, we need to be able to get hold
of the exit node $\exit(q)$ in $T$ for any given element 
$q \in \{0, 1\}^w$. To make sure that this can be done explicitly,
we need $\exit(q)$ lies at the correct level of $T$. Since this
does not necessarily need to be the case, we use a trick of 
Bose~\etal~\cite{BoseDoDuHoMo13}.
The idea is to perform a random shift of the universe to
make sure that the distance between two fixed elements
is reflected by the length of their longest common prefix. 
More precisely, we pick a random $r \in \{0, 1\}^w$, and we
add $r$ to all query and update elements that appear in 
the data structure (modulo $2^w$). Then, we have
the following lemma, whose proof we include for completeness:

\begin{lemma}[Lemma 4 in \cite{BoseDoDuHoMo13}]
\label{lemma:delta_lca_loglog_delta}
Let $x, y \in \{0, 1\}^w$ be two fixed bitstrings.
Let $r \in \{0, 1\}^w$ be picked uniformly at random.
After a random shift of $\{0, 1\}^w$ by $r$, the 
expected height of the lowest common ancestor of 
$x$ and $y$ in a compressed trie is $O(\log|x - y|)$.\qed
\end{lemma}

\begin{proof}
\wolfgang{Maybe we should repeat the proof, adapt to our technology,
and make it also work for long prefixes}
\end{proof}

\begin{corollary}
\label{cor:delta_fast_expected_lca}
Let $S \subseteq \{0, 1\}^w$ and let $T$ be 
a compressed trie $S$, shifted by a random offset
$r \in \{0, 1\}^w$.
Let $q \in \{0, 1\}^w$. 
We can find the exit node for $q$  in expected time $O(\log\log d(q, S))$.
The expectation is
over the random choice of the shift $r$. 
\end{corollary}

\begin{proof}
Suppose without loss of generality that $d(q, S) = |q - q^-|$.
By Lemma~\ref{lemma:delta_lca_loglog_delta},
the expected height $2^{2^i}$ of the lowest common ancestor of $q$ and $q^-$
is $O(\log d(q, S)$.
We perform the doubly exponential
search on the prefixes of $q$, as in Algorithm~\ref{algo:pred-short}
(without computing $\widehat f (p - 1)$ or $\widehat f (p + 1)$) 
to find the height $2^{2^i}$. After
that, we  use a fat binary search to find the
exit node.
Since $2^{2^i} = O(\log d(q, S))$ in expectation,
it follows by Jensen's inequality that the number $i$
of loop iterations to find  the height is $O(\log\log\log d(q, S))$
in expectation. Thus, the expected running time is proportional to
$i + \log 2^{2^i} = O(\log\log d(q, S))$. 
\end{proof}

\subsubsection{Implementing the Range Locator}

To implement a dynamic range locator, 
we need to maintain for each node $v \in T$ the
leftmost and the rightmost element in the subtree $T_v$.
To update this fast, we use an additional data structure.

\begin{figure}
\centering
\includegraphics{pathdecomp}
\caption{For each leaf $v'$ of $T$, we connect the nodes
$v \in T$ by a dashed line for which $v$ is the leftmost leaf in $T_v$.
Considering these
subpaths for all leaves in $T$, we obtain a \emph{path decomposition}
of $T$ (shown in dashed).}
\label{fig:pathdecomp}
\end{figure}
To do this, we observe the following: let $v' \in T$ be 
a leaf in $T$. Then, $v'$ is the leftmost (or rightmost)
leaf in the subtrees of at most $w$ ancestors $v$ of $v'$.
Furthermore, all these nodes form a subpath (more precisely,
a prefix) of the path from $v$ to the root, see Figure~\ref{fig:pathdecomp}.
Hence, if we maintain the nodes of 
this subpath in a concatenable queue data structure
(realized by, e.g., a balanced binary tree)~\cite{PreparateSh85},
we can obtain $O(\log w)$ update and query time
to find the leftmost (or rightmost) element in $T_v$
for each $v \in T$.
However, we need that the update and query time for this
data structure
depend on the \wolfgang{TODO: adapt terminology} height  
of the query node $v$.
Thus, we partition the possible heights
$\{0, 1, \dots, w\}$ of the nodes on a 
subpath into the sets
$T_{-1} = \{0\}$, $T_i =[2^i, 2^{i+1})$, for $i = 0,\dots,\log w-1$, 
and $T_{\log w} = \{w\}$.
Each set is managed by a balanced binary tree, and the 
roots of the trees are linked together. The height of the $i$-th binary 
search tree is $\log |T_i| = O(i)$. Furthermore, if a query node
of height $h$ is given, 
the set $T_{\lfloor \log h \rfloor}$ is responsible for it, see 
Figure~\ref{fig:queryds}.
\begin{figure}
\centering
\includegraphics{queryds}
\caption{The data structure for a subpath. We group the nodes
in the subpath according to their heights, where the groups
grow exponentially in size. Each group is represented by a
balanced tree. The roots are joined in a linked
list. With this data structure, a node $v$ of height $h$ can
find the leftmost leaf in the subtree $T_v$ in time $O(\log h)$.}
\label{fig:queryds}
\end{figure}


Moreover, $T_{-1}$ is a leaf (the depth of that node is $w$) 
in the trie and therefore the minimum of the whole subpath. Thus, 
the minimum of a subpath can be found from a given node 
$v \in T_i$ in $O(i)$ time by following the
pointers to the root of $T_i$ and the pointers down to $T_{-1}$.

If a node $v$ has $h_k = O(\log d(q, S)$ height (remaining bits), 
the node is within
the tree $T_{\lfloor \log h_k \rfloor}$. Thus, it takes 
$O(\log h_k) = O(\log\log\Delta)$ time to find the leftmost
or rightmost leaf in $T_v$.

Furthermore, we can support the following update operations:
(i) \textbf{split}: given a subpath $\pi$ and a node $v$ on $\pi$, split 
the representation of $\pi$ into two representations, one for the 
\emph{lower} subpath from the leaf up to the child of $v$, and
one for the \emph{upper} subpath starting from $v$; and (ii) 
\textbf{join}: given a
representation of an upper subpath starting at a node $v$ obtained 
from an operation of type (i), and a representation for 
a lower subpath up to a child of $v$, join the two representations
into the representation for a joint subpath.
Given the data structure, we can support
both \textbf{split} and \textbf{join} in
 $O(\log h)$ time, where $h$ is the height of 
the node $v$ where the operation occurs. 
This decomposition of $T$ into dynamically changing suppaths
is similar to the \emph{preferred paths decomposition} of
Tango trees~\cite{DemaineHaIaPa07}.

\subsubsection{Performing an Update}

We know from the Lemma~\ref{lemma:delta_lca_loglog_delta}, that 
the lowest common ancestor of a query element $q$ has expected 
height $h_k = O(\log \Delta)$.

\begin{lemma}
\label{lemma:delta_insert}
Let $S \subseteq U$, and let $T$ be
a randomly shifted $\Delta$-fast tree for 
$S$.  Let $q \in U$ be fixed.
We can insert or delete $q$ into $T$
in $O(\log \log \Delta)$ expected time, where the expectation is 
over the random choice of the shift $r$.
\end{lemma}

\begin{proof}
To insert $q$ into $T$, we need to split an edge $(u,v)$ of $T$ into
two edges $(u,b)$ and $(b,v)$. This creates
exactly two new nodes in $T$, an inner node and a leaf node. 
The branch node is exactly $\lca_T(q)$, and it has expected height 
$h_k = O(\log \Delta)$, by Lemma~\ref{lemma:delta_lca_loglog_delta}. 
Thus, it will
take $O(\log\log \Delta)$ expected time to find
the edge $(u,v)$, by
Corollary~\ref{cor:delta_fast_expected_lca}.

Once the edge $(u,v)$ is found, the hash maps $H_z$ and $H_u$ 
can then be updated in constant time.
Now let us consider the update time of the 
hash map $H_\Delta$. Recall that
$H_\Delta$ stores the lowest branch nodes for all prefixes
of the elements in $S$ that have certain lengths.
This means that all prefixes on the edge $(b,v)$ which 
are stored in the hash map $T_\Delta$ need to
be updated. Furthermore, prefixes at certain depths which 
are on the new edge $(b,q)$ need to
be added. For the edge $(b,v)$, we will enumerate 
all prefixes at certain depths, but we will select only those that 
lie on the edge $(b,v)$. This needs
$O(\log\log\log\Delta)$ insertions and updates in total: we
have to insert the prefixes $q_0 \dots q_{d_i}$ for all 
$i \geq 1$ with $d_i < |b|$. Since we defined 
$d_i = w - h_i = w - 2^{2^i}$, 
and since $|b| = w - O(\log \Delta)$, 
we have that $d_i \leq |b|$ as soon as 
$c \log\Delta < 2^{2^i}$. This holds for 
$i > \log\log (c\log \Delta)$, and hence $i =
\Theta(\log\log\log\Delta)$.

After that, the leftmost and rightmost elements for the subtrees
of $T$ have to be updated. For this, we need to add one
subpath for the new leaf $q$, and we may need to split
a subpath at a node of height $h_k = O(\log \Delta)$ and join
the resulting upper path with the newly created subpath. As we
have seen, this takes $O(\log h_k) = O(\log \log \Delta)$ time.

The operations for deleting an element $q$ from $S$ are symmetric.
\end{proof}

The following theorem summarizes our result.

\begin{theorem}
Let $r \in U$ be picked uniformly at random.
After performing a shift of $U$ by $r$, 
the $\Delta$-fast trie provides a data structure for the
dynamic predecessor problem such that the 
query operations take $O(\log \log \Delta)$ worst-case time and 
the update operations need $O(\log \log \Delta)$ expected
time, for $\Delta = \min \{|q-q^+|, |q-q^-|\}$, where $q$ is the
requested element and $q^+$ and $q^-$ are the predecessor and
successor of $q$ in the current set $S$. At any point in time, 
the data structure needs $O(n)$ words of space, where $n = |S|$.
\end{theorem}


\subsubsection{Applications}

Bose~\etal~\cite{BoseDoDuHoMo13} describe how to combine their structure
with a technique of Chan~\cite{Chan02} and random 
shifting~\cite[Chapter~11]{HarPeled11} for obtaining a data structure for 
distance-sensitive
approximate nearest neighbor queries on a grid.
More precisely, let $d \in \N$ be the fixed dimension, 
$U = \{0, \dots, 2^{w}-1\}$ be the universe, and
let $\eps > 0$ be given.
The goal is to maintain a dynamic set $S \subseteq U^d$ under
insertions, deletions, and \emph{$\eps$-approximate
nearest neighbor queries}: given a query point $q \in U^d$,
find a $p \in S$ with $d_2(p,q) \leq (1+\eps)d_2(p, S)$.
Plugging our $\Delta$-fast tries into the structure of
Bose~\etal~\cite[Theorem~9]{BoseDoDuHoMo13}, we can
immediately improve the space requirement of their structure to linear:
\begin{theorem}
Let $U = \{0, \dots, 2^w-1\}$ and let $d$ be a constant.
Furthermore, let $\eps > 0$ be given.
There exists a data structure that supports $(1+\eps)$-approximate
nearest neighbor queries over a subset $S \subseteq U^d$ in 
$(1/\eps^d)\log\log \Delta)$ expected time and insertions and deletions
of elements of $U^d$ in $O(\log\log \Delta)$ expected time.
Here, $\Delta$ denotes the Euclidean distance between the query element
and $S$. At any point in time, the data structure requires $O(n)$
words of space, where $n  = |S|$.
\end{theorem}

As a second application, Bose~\etal~\cite{BoseDoDuHoMo13}
present a data structure for dominance queries on a grid,
based on a technique of Overmars~\cite{Overmars88}.
Again, let $U = \{0, \dots, 2^w-1\}$, and let $S \subseteq U^2$,
$|S| = n$ be given. The goal is to construct a data structure
for \emph{dominance queries} in $S$. That is, given a query point
$q \in U^2$, find all points $p$ in $S$ that \emph{dominate} $q$,
i.e., for which we have $p_x \geq q_x$ and $p_y \geq q_y$, there
$p_x$, $p_y$ and $q_x$, $q_y$ are the $x$- and $y$-coordinates 
of $p$ and $q$.

Again, using $\Delta$-fast tries, we can immediately improve the
space requirement for the result of 
Bose~\etal~\cite[Theorem~10, Corollary~13]{BoseDoDuHoMo13}.

\begin{theorem}
Let $U = \{0, \dots, 2^w-1\}$, and let $S \subseteq U^2$, $|S|=n$
be given. There exists a data structure that reports the points in $S$
that dominate a given query point $q = (a,b) \in U^2$ in expected time
$O(\log\log(h+v) + k)$, where $h = 2^w - a$, $v = 2^2-b$, and $k$
is the number of points in $S$ dominated by $q$.
The data structure uses $O(n \log n)$ space.
\end{theorem}


\section{Globally sensitive predecessor search}

We can apply Theorem~\ref{thm:pred-long} to improve 
exponentially over the bound by Demaine, Jones, and 
\Patrascu~\cite{DemaineJoPa04}, which gives an algorithm whose running time
depends on the largest and smallest distance between the elements of $S$. 
More precisely, let
$\Delta_M$ and $\Delta_m$ be, respectively, the largest and smallest distance
between two consecutive elements of $S$.
\begin{corollary}
\label{cor:deltadelta}
Using an index of $O(n\log w)$ bits, it is possible to answer predecessor
queries in time $O(\log\log(\Delta_M/\Delta_m))$.
\end{corollary}
\begin{proof}
We use a standard ``universe reduction'' argument, splitting 
the universe $2^w$ by grouping strings sharing the most significant $\lceil \log
n\rceil$ bits. Each subuniverse $U_i$ has size $2^{w-\lceil \log
n\rceil}=O(2^w/n)$, and we let $S_i=S\cap U_i$. Using a constant-time
prefix-sum data structure we keep track of the rank in $S$ of the smallest
element of $S_i$, and we build the indices that are necessary for
Algorithm~\ref{algo:pred-long} for each $S_i$ (seen as a set of strings of
length $w-\lceil \log
n\rceil$). Thus, we can answer a query $x$ in time $O(\log(w-\lceil \log
n\rceil -\log D(x,S_i))$, where $U_i$ is the subuniverse containing $x$. Now
note that $\Delta_M\geq 2^w/n$, and that $\Delta_m\leq x^+-x^-
=(x^+-x)+(x-x^-)\leq 2D(x,S)\leq 2D(x,S_i)$ (unless $x$ the smallest or the
largest element of $S_i$, but this case can be dealt with in constant time). The
bound follows immediately.
\end{proof}

\section{Finger predecessor search}

We conclude with a generalisation of long-distance search that builds on previous results~\cite{BelazzouguiBoPaVi11b}.
Using $O(n w^{1/c})$ bits (for any $c$) it
is possible to answer \emph{weak prefix search} queries in constant time. A weak
prefix search query takes a prefix $p$ and returns the leftmost and rightmost
index of elements of $S$ that are prefixed by $p$; if no such element exists,
the results are unpredictable (hence the ``weak'' qualifier), but a single access to the set $S$ is sufficient
to rule out this case and always get a correct result. Thus, we will be
able to compute $\lrange(-)$, $\rrange(-)$ and $\extent(-)$ on arbitrary
elements of $\Pref(S)$ in constant time. As a consequence, also $\pred(x,t)$ can
be extended so to return a correct value for every $t$ such that
$x[0\..t)\in \Pref(S)$.

The basic idea of Algorithm~\ref{algo:finger} is that of using a \emph{finger}
$y\in S$ to locate quickly an extent $e$ that is a prefix of $x$ with the guarantee that $w-|e|\leq\log|x-y|$. The extent
is then used to accelerate an algorithm essentially identical
Algorithm~\ref{algo:pred-long}, but applied to a reduced universe (the strings
starting with $e$); the running time thus becomes
$O(\log(w-|e|-\log D(x,S)|)=O(\log(\log|x-y|-\log D(x,S)))$.

\begin{algorithm}
\KwIn{a nonempty string $x\in 2^w$ and a $y\in S$ such that $y<x$}
\KwOut{index $i$ such that $S[i]=x^-$}

$t \gets \max\{\,s\mid y[0\..s)+1\preceq x\,\}$\;
$e \gets \extent(y[0\..t)+1)$\;
\If{$y[0\..t)+1\not\preceq e$}{%
  \Return $\rrange(y[0\..t))$
}
\tcp{$y[0\..t)+1\not\in\Pref(S)$} 
\If{$e\not\prec x$}{% 
  \Return{$\pred(x,t)$}
}
\tcp{$x$ exits between $y[0\..t)+1$ and $e$} 
$a \gets 0$\;
\tcp{Now $e\prec x$ and $w-|e|\leq\log|x-y|$} 
\While{$a<(w-|e|)/2$}{%
  $m \gets \text{least power of 2 in $(a-|e|\..w-|e|)$}$\;
  $p \gets x[0\..m+|e|)$
  \If{$p\not\in\Pref(S)$}{%
    \Return $\fbs^-(x,a+|e|,m+|e|)$
  }
  \If{$S[\lrange(p)]\geq x$}{%
    \Return{$\lrange(p)-1$}
  }
  \If{$S[\rrange(p)] < x$}{%
    \Return{$\rrange(p)$}
  }
  $a \gets |\extent(p)|-|e|$ 
  \tcp{This is a valid extent}
}
\Return{$\fbs^-(x,a+|e|,w)$}
\caption{\label{algo:finger}Long-distance finger-search speedup.}
\end{algorithm}


\begin{theorem}
\label{th:finger}
Algorithm~\ref{algo:finger} returns the predecessor of an input string $x$ given
a finger $y\in S$, with $y<x$, in time $O(\log(\log|x-y|-\log D(x,S)))$ using an 
index of $O(n w^{1/c})$ bits 
of space, for any $c$ (in addition to the space needed to store the elements of $S$).
\end{theorem}
\begin{proof}
First we show that the algorithm is correct. 
If we exit at the first return instruction, $y[0\..t)+1$ is
not in $\Pref(S)$, which implies that $x^-$ is prefixed by $y[0\..t)$, and thus
the output is correct. If we exit at the second return instruction, $x$
exits at the same node as $y[0\..t)+1=x[0\..t)$. Otherwise, $e$ is an extent
that is a proper prefix of $x$, and the remaining part of the algorithm
is exactly Algorithm~\ref{algo:pred-long} applied to the set of strings of $S$ 
that are prefixed by $e$, with $e$ removed (the algorithm is slightly
simplified by the fact that we can test membership to $\Pref(S)$ and compute
extents for every prefix). Correctness is thus immediate.

All operations are constant time, except for the last loop. Note that as soon as
$m+|e|\geq w-\log D(x,S)$ the loop ends or a prefix of $x$ is found (as in the
proof of Algorithm~\ref{algo:pred-long}), and this requires no more than $\log(w-|e|-\log
D(x,S))$ iterations; moreover, $m\leq 2a$ (because there is always
a power of $2$ in the interval $(a\..2a]$), so the fat binary search in the first
return will take no more than $\log(m-a)\leq \log a\leq \log (w-|e|-\log D(x,S))$.
If the loop exits naturally, then there is a prefix $e'$ of $x$ belonging
to $\Pref(S)$ and longer than $(w+|e|)/2$, hence by
Lemma~\ref{lemma:shortinprefs}, $w-\log D(x,S)\geq (w+|e|)/2$; the fat binary search at the
end takes time $O(\log (w-(a+|e|)))=O(\log (w-|e'|))=O(\log( w/2 -
|e|/2)))=O(\log(w-|e|-\log D(x,S)))$, within the prescribed time bounds.
\end{proof}

\section{Delta-Fast Abstract}
Let $w \in \N$ and $U = \{0, 1, \dots, 2^w-1\}$ be a 
bounded universe of $w$-bit integers.  We present a 
dynamic data structure for predecessor searching in 
$U$.  Our structure needs $O(\log \log \Delta)$ time 
for queries and $O(\log \log \Delta)$ expected time 
for updates, where $\Delta$ is the difference between 
the query element and its nearest neighbor in the 
structure. Our data structure requires linear space. 
This improves a result by Bose~\etal [CGTA, 46(2), pp.~181--189].

The structure can be applied for answering approximate nearest
neighbor queries in low dimensions and for dominance queries on
a grid.

\section{Introduction}

Predecessor searching is one of the oldest problems in 
theoretical computer science~\cite{CormenLeRiSt09,Knuth98}.
Let $U$ be a totally ordered universe. The task
is to maintain a set $S \subseteq U$,
while supporting
\emph{predecessor} and \emph{successor} queries: 
given $q \in U$, find the largest element in $S$ 
smaller than $q$ ($q$'s predecessor) or the 
smallest element in $S$ larger than $q$
($q$'s successor). In the \emph{dynamic}
version of the problem, we also want to 
be able to modify $S$ by inserting and/or 
deleting elements.

On the \emph{word-RAM},
all input elements are $w$-bit words, where
$w \in \N$ is a parameter. Without loss of 
generality, we may assume that $w$ is a power 
of $2$. We are allowed to manipulate the input 
elements at the bit level, in constant time per 
operation. In this case, we may assume that the 
universe is $U = \{0, \dots, 2^{w}-1\}$. 
A classic solution for predecessor searching on the
word-RAM is due to van Emde Boas, who
described a dynamic data structure that
requires space $O(n)$ and supports insertions,
deletions, and predecessor queries in $O(\log\log |U|)$ 
time~\cite{vEmdeBoas77,vEmdeBoasKaZi76}.

In 2013, Bose~\etal~\cite{BoseDoDuHoMo13} described
a word-RAM data structure for the predecessor
problem that is \emph{local} in the following sense.
Suppose our data structure currently contains the
set $S \subseteq U$, and let $q \in U$ be a query
element.  Let $q^+ := \min\{s \in S \mid s \geq q \}$ and
$q^- := \max\{s \in S \mid s \leq q \}$ be the 
successor and the predecessor of $q$ in $S$, and let
$\Delta= \min\{|q- q^-|, |q-q^+|\}$ be the distance
between $q$ and its nearest neighbor in $S$. Then, 
the structure by Bose \etal can answer predecessor 
and successor queries in $O(\log\log \Delta)$ time.
Their solution requires $O(n \log\log\log|U|)$ words 
of space, where $n = |S|$ is the size of the 
current set. Bose~\etal apply their structure 
to obtain a fast data structure for approximate nearest 
neighbor queries in low dimensions and for answering
dominance and range searching queries on a grid.

Here, we show how to obtain a data structure with similar
guarantees for the query and update times that reduces the
space requirement to $O(n)$. This solves an open problem 
from~\cite{BoseDoDuHoMo13}. Furthermore,  this also improves the space 
requirement for data structures for nearest neighbor searching
and dominance reporting.
Full details and pseudocode for all the algorithms and
data structures described here can 
be found in the Master's thesis of the first author~\cite{Ehrhardt15}.
Belazzougui~\etal give a linear space bound for distance-sensitive
queries in the static setting, using almost the same 
techniques as in the present paper~\cite{BelazzougiBoVi12}. Our 
result was obtained independently from the work of 
Belazzougui~\etal

\section{Preliminaries}
\label{sec:prelim}

We begin by listing some known structures and background information
required for our data structure.

\paragraph{Compressed Tries.}
Our data structure is based on \emph{compressed
tries}~\cite{CormenLeRiSt09}. These are defined as
follows: we interpret the elements from $S$ as bitstrings 
of length $w$ (the most significant bit being in the leftmost
position). The \emph{trie} $T'$ for $S$ is a binary tree
of height $w$. Each node $v \in T'$ corresponds
to a bitstring $p_v \in \{0,1\}^*$. The root $r$ has
$p_r = \eps$. For each inner node $v$, the left
child $u$ of $v$  has $p_u = p_v0$, and the
right child $w$ of $v$ has $p_w = p_v1$ (one of the
two children may not exist). The bitstrings of the 
leaves correspond to the elements of $S$, and
the bitstrings of the inner nodes are prefixes
for the elements in $S$, see Figure~\ref{fig:trie}.

The \emph{compressed trie} $T$ for $S$ is obtained
from $T'$ by contracting each maximal path of nodes
with only one child into a single edge. 
Each inner node in $T$ has exactly two children, and
consequently $T$ has $O(n)$ nodes.
Maybe somewhat unusually, in the following, the 
\emph{height} and \emph{depth} of a node $v$ in $T$ 
will refer to the corresponding
height and depth in the (uncompressed) trie $T'$.
This convention will make the description of the operations more
convenient.

Let $q \in \{0,1\}^*$ be a bitstring of length at most $w$.
The \emph{longest common prefix} of $q$ with $S$, $\lcp_S(q)$,
is the longest prefix that $q$ shares with an element 
in $S$. We say that $q$ \emph{lies on an edge}
$e = (u, v)$ of $T$ if $p_u$ is a prefix of $q$ and
$q$ is a proper prefix of $p_v$. If $\lcp_S(q)$
lies on the 
edge $(u,v)$, we call $u$ the \emph{lowest common
ancestor} of $q$ in $T$, denoted by
$\lca_T(q)$. One can show that $\lca_T(q)$ is uniquely
defined.

\paragraph{Associated Keys.}
Our algorithm uses the notion of
\emph{associated keys}. This notion
was introduced in the context of 
\emph{$z$-fast tries}~\cite{BelazzouguiBoVi10,Ruzic09},
and it is also useful in our data structure.

Associated keys provide a quick way to compute $\lca_T(q)$,
for any element $q \in U$.
A natural way to find $\lca_T(q)$ is
to do binary search on the depth of $\lca_T(q)$:
we initialize $(l,r) = (0,w)$ and let 
$m = (l+r)/2$. We denote by $q' = q_0\dots q_{m-1}$ 
the leftmost $m$ bits of $q$, and we check whether
$T$ has an edge $e = (u,v)$ such that $q'$ lies on $e$.
If not, we set $r = m$, and we continue.
Otherwise, we determine if $u$ is $\lca_T(q)$, by
testing whether $p_v$ is not a prefix of $q$.
If $u$ is not $\lca_T(q)$, we set $l = m$ and continue.
In order to perform this search quickly,
we need to find the edge $e$ that
contains a given prefix $q'$, if it exists. For this,
we precompute for each edge $e$ of $T$
the first time that the binary search
encounters a prefix that lies on $e$. This
prefix is uniquely determined and depends only on 
$e$, not on the specific string $q$ that we are looking 
for. We let $\alpha_e$ be
this prefix, and we call $\alpha_e$ the \emph{associated key}
for $e = (u,v)$, see Figure~\ref{fig:binsearch}. 
\begin{figure}
\centering
\includegraphics{binsearch_assoc_key_main}
\caption{The associated key $\alpha_e$ of an edge $e$:
we perform a binary search on the height of
$\lcp_S(q)$ in $T$. The \emph{associated key}
of an edge $e$ is the prefix of $\lcp_S(q)$ in which the
search first encounters the edge $e$. }
\label{fig:binsearch}
\end{figure}


The binary search needs $\log w$ steps, and 
since we assumed that $w$ is a power of two,
each step determines the next bit in the binary 
expansion of the \emph{length} of $\lcp_S(q)$.
Thus, the associated key of an edge $e$
can be computed in $O(1)$ time on a word RAM 
as follows: consider the $\log w$-bit binary 
expansions $\ell_u = |p_u|_2$ and  $\ell_v = |p_v|_2$ of the
\emph{lengths} of the prefixes
$p_u$ and $p_v$, and let $\ell'$ be the
longest common prefix of $\ell_u$ and
$\ell_v$. We need to determine the first
step when the binary search can distinguish between
$\ell_u$ and $\ell_v$. Since $\ell_u < \ell_v$,
and since the two binary expansions differ in the
first bit after $\ell'$,
it follows that $\ell_u$ begins with $\ell'0$ and
$\ell_v$ begins with $\ell'1$. Thus, let $\ell$ be obtained
by taking $\ell'$, followed by $1$ and
enough $0$'s to make a $\log w$-bit
word. Let $l$ be the number encoded by $\ell$.
Then, the associated key $\alpha_e$ consists of the 
first $l$ bits of $p_v$;
see~\cite{BelazzouguiBoVi10,Ehrhardt15,Ruzic09} for more details.

\paragraph{Hash Maps.}
Our data structure also makes extensive use of
hashing. In particular, we will maintain several
succinct hashtables that store additional
information for supporting fast queries.
For this, we will use a hashtable described
by Demaine~\etal~\cite{DemaineMePaPa06}.
The following theorem summarizes the properties
of their data structure.

\begin{theorem}
For any $r \geq 1$, there exists a dynamic dictionary that
stores entries with keys from $U$ and with associated
values of $r$ bits each.
The dictionary supports updates and queries in $O(1)$ time,
using $O(n \log\log (|U|/n) + nr)$ \emph{bits} of space.
The bounds for the space and the queries are
worst-case, the bounds for the updates hold with
high probability.\qed
\end{theorem}

\section{Static $\Delta$-fast Tries}
\label{sect:delta-fast_trie}

We are now ready to describe our data structure 
for the static case. In the next section, we will
discuss how to add support for insertions and
deletions.

\subsection{The Data Structure}
Our data structure is organized as follows:
let $S \subseteq U$, $|S| = n$, be given.
We store $S$ in a compressed trie
$T$. The leaves of $T$ are
linked in sorted order. Furthermore, 
for each node $v$ of $T$, let $T_v$ be the
subtree rooted at $v$. Then, $v$ stores pointers 
to the smallest and the largest leaf in 
$T_v$. To support the queries, we store 
three additional hash maps: $H_\Delta$, $H_z$,
and $H_b$.

First, we describe the hash map $H_\Delta$.
Set $m = \log\log w$. For
$i = 0, \dots, m$, we let
$h_i = 2^{2^i}$ and  
$d_i = w - h_i$. 
The hash map $H_\Delta$ stores the following
information: for each $s \in S$ and each
$d_i$, $i = 1, \dots, m$,
let $s_i = s_0 \dots s_{d_i-1}$ be the leftmost
$d_i$-bits of $s$ and let $e = (u,v)$ be
the edge of $T$ such that $s_i$ lies
on $e$.
Then, $H_\Delta$ stores the entry
$s_i \mapsto u$.

Next, we describe the hash map $H_z$.
It is defined similarly as the hash map
used for $z$-fast tries~\cite{BelazzouguiBoVi10,Ruzic09}.
For each edge $e$ of $T$, let $\alpha_e$ be
the associated key of $e$, as explained in 
Section~\ref{sec:prelim}.
Then, $H_z$ stores the entry $\alpha_e \mapsto e$.


Finally, the hash map $H_b$ is used to implement
a second layer of indirection that lets us achieve
linear space. It will be described below.

\subsection{The Predecessor Query}
\label{sec:staticquery}

Let $q \in U$ be the query, and let
$q^-$ and $q^+$ be the predecessor and
the successor of $q$ in $S$, as described above.
We first show how to get a running time
of $O(\log\log \Delta)$ for the queries, with  
$\Delta = |q - q^+|$.  In Theorem~\ref{thm:staticresult}, we will 
see that this can easily be improved
to $\Delta = \min\{|q - q^-|, |q - q^+|\}$.

The predecessor search works in several 
\emph{iterations}. In iteration $i$, we consider
the prefix $q_i$ that consists of the first $d_i$ 
bits of $q$.

First, we check whether 
$H_\Delta$ contains an entry for
$q_i$. If so, we know that $T$ contains
an edge $e$ such that $q_i$ lies on $e$.
Hence, $q_i$ must be  a prefix of $\lcp_S(q)$.
If one of the endpoints of $e$ happens to be
$\lca_T(q)$, we are done.
Otherwise, we consider the two edges emanating from  the lower
endpoint of $e$, finding the edge $e'$ that lies on
the path to $q$.
We take the associated key $\alpha_{e'}$ of $e'$,
and we use it to continue the binary search
for $\lca_T(q)$, as described in
Section~\ref{sec:prelim}. Since $|q_i| = d_i$,
this binary search takes 
$O(\log (w - d_i)) = O(\log h_i)$ steps to complete.
Once the lowest common ancestor $v = \lca_T(q)$ is 
at hand,  we can find the predecessor of $q$ in $O(1)$ 
additional time: it is either the rightmost element in $T_v$,
the predecessor of the leftmost element in $T_v$, or the 
rightmost element in the left subtree of $v$. Given the 
pointers stored with $v$ and the leaves of $T$, all these
nodes can be found in $O(1)$ time.

If $H_\Delta$ contains no entry for
$q_i$ and if $q_i$ does not consist
of all $1$'s, we check if $H_\Delta$ contains
an entry for $q_i + 1$.
Notice that $q_i+1$ is the successor of $q_i$. 
If such an entry exists,
we first obtain $u = H_\Delta[q_i +1]$, and the child $v$ of 
$u$ such that $q_i + 1$ lies on the edge $e = (u,v)$.
Then, we follow the pointer to the leftmost element of
$T_v$. This is the successor $q^+$ of $q$. 
The predecessor $q^-$ can then be found by following the 
leaf pointers. This takes $O(1)$ time overall.

Finally, if there is neither an entry for $q_i$
nor for $q_i+1$, we continue 
with iteration $i+1$, see Figure~\ref{fig:query}.

\begin{figure}
\centering
\includegraphics[scale=0.5]{query}
\caption{The query algorithm: first we perform an
exponential search from the lowest level, to find a prefix
of $q_k$  or $q_k+1$ (left). If a prefix $q_{k}$ is found,
we perform a binary search for $\lca_T(q)$ (middle), which can then
be used to find the predecessor and successor of $q$ (right). If
a prefix $q_k+1$ is found, the successor and predecessor 
can be found immediately (not shown).}
\label{fig:query}
\end{figure}

From the above discussion, it follows that
the total time for the predecessor
query is $O(k + \log h_k)$, where $k$ is the number of 
iterations and $\log h_k$ is the worst-case time 
for the predecessor search once one of the lookups 
in an iteration succeeds. 
By our predecessor algorithm, we know that $S$ contains no element with
prefix $q_{k-1}$ or $q_{k-1} + 1$, but an element with
prefix $q_k$ or $q_k + 1$. Thus, there must be
at least $2^{w - d_k} = 2^{h_k}$ consecutive elements in 
$U\setminus S$ following $q$. By our definition of $h_k$, it follows that
$\Delta \geq 2^{h_{k-1}} = 2^{2^{2^{k-1}}}$, so 
$k \leq 1 + \log\log\log \Delta$.
Furthermore, since $h_k = 2^{2^k} = \left(2^{2^{k-1}}\right)^2 
=  (h_{k-1})^2$, 
it follows that $h_k = O(\log^{2} \Delta)$.

\subsection{Obtaining Linear Space}
We now analyze the space requirement for our
data structure.
Clearly,  the  trie $T$ and the
hash map $H_z$ require $O(n)$ words of space.
Furthermore, as described so far, the number of 
words needed for
$H_\Delta$ is $O(n \log\log w)$, since 
we store at most $n$ entries for each 
height $h_i$, $i = 0, \dots, m = \log\log w$.

Using a trick due to P\v{a}tra\c{s}cu~\cite{Patrascu10}, 
we can introduce another level of indirection to reduce 
the space requirement to  $O(n)$.
The idea is to store in $H_\Delta$ the \emph{depth}
$d_u$ of each branch node $u$ in $T_\Delta$, instead of storing 
$u$ itself (here, we mean the depth in the
original trie, i.e., the length of the prefix $p_u$). 
We then use an additional hash map 
$H_b$ to obtain $u$.
This is done as follows:
when trying to find the branch node $u$ for a given
prefix $q_i$, we 
first get the depth $d_u = |p_u|$ of $u$ 
from $H_\Delta$. After that, we look up the branch
node $u = H_b[q_0 \dots q_{d_u-1}]$ from the hash map 
$H_b$. Finally, we check whether $u$ is actually the 
lowest branch node of $q_i$. If any of those steps fails,
we return $\bot$.

Let us analyze the needed space: clearly, $H_b$ needs
$O(n)$ words, since it stores $O(n)$ entries.
Furthermore,
we have to store $O(n \log\log w)$ entries in 
$H_\Delta$, each mapping a prefix $q_i$ to the depth of 
its lowest branch node. This depth requires
$\lceil \log w \rceil$ bits.
By Theorem~\ref{thm:succinct_retrieval_only_hashtable},
a retrieval only hash map for $n'$ items and $r$ bits 
of data needs $O(n'\log\log \frac{|U|}{n'} + n'r)$ bits.
Therefore, the space 
\emph{in bits} for $H_\Delta$ is proportional to
\begin{align*}
&\phantom{=} n \log\log w \cdot \log\log \frac{|U|}{n \log\log w} +
n \log\log w \cdot \lceil \log w \rceil\\
&= O(n \log\log w \cdot \log w)\\
&= o(n\cdot w),
\end{align*}
using $n' = n\log\log w$, $r = \lceil \log w \rceil$ and $w = \log |U|$. 
Thus, we can store $H_\Delta$ in 
$O(n)$ words of $w$ bits each. The following lemma summarizes
the discussion

\begin{lemma}
\label{lemma:delta_linear_space}
The $\Delta$-fast trie needs $O(n)$ words space.
\end{lemma}

\subsection{Putting it Together}

We can now obtain our result for the static predecessor problem.

\begin{theorem}\label{thm:staticresult}
Let $U = \{0, \dots, 2^{w}-1\}$ and let
$S \subseteq U$, $|S| = n$.
The static $\Delta$-fast trie for $S$ requires
$O(n)$ words of space, and it can answer
a static predecessor query for an element $q \in U$ on $S$ in time
$O(\log \log \min\{|q-q^-|, |q-q^+|\})$,
where $q^-$ and $q^+$ denote the predecessor
and successor of $q$ in $S$.
The preprocessing time is 
$O(n \log\log \log |U|)$, assuming that
$S$ is sorted.
\end{theorem}

\begin{proof}
The regular search for $q \in S$ can be done in 
$O(1)$ time by a lookup in $H_z$. 
We have seen that the predecessor of $q$
can be found in $O(\log \log |q-q^+|)$ time.
A symmetric result also holds for 
successor queries.
In particular, we can achieve query time 
$O(\log \log |q-q^-|)$  by checking for
$H_\Delta[q_i-1]$ instead of $H_\Delta[q_i+1]$ in the 
query algorithm. 

By interleaving the two searches,
we obtain the desired running time of 
$O(\log\log \min\{|q - q^-|, |q - q^+|\})$. 
Of course, in a practical implementation, it would be 
more efficient to check directly for $H_\Delta[q_i-1]$
and $H_\Delta[q_i+1]$ in the query algorithm.

The trie $T$ and the hash maps $H_z$
and $H_b$ can be computed in $O(n)$ time, given that
$S$ is sorted.
Thus, the preprocessing time is dominated by the time to fill the 
hash map $H_\Delta$.  Hence, the preprocessing needs
$O(n\log\log\log |U|)$ steps, because $O(n\log\log w)$ nodes 
have to be
inserted into $H_\Delta$. 
By Lemma~\ref{lemma:delta_linear_space}, the space requirement
is linear.
\end{proof}

\section{Dynamic $\Delta$-fast tries}

\section{Conclusion}

We present a new data structure for local searches
in bounded universes. This structure now interpolates
seamlessly between hashtables and van-Emde-Boas trees,
while requiring only a linear number of words. This provides
an improved, and in our opinion also slightly simpler, version
of a data structure by Bose \etal~\cite{BoseDoDuHoMo13}.
All the operations of our structure can be
presented explicitly in pseudocode. This can be found in the
Master's thesis of the first author~\cite{Ehrhardt15}.

\bigskip
\noindent\textbf{Acknowledgments.}
We thank the anonymous reviewers for numerous
insightful comments that improved the quality of the paper.
\wolfgang{TODO}

\hyphenation{ Vi-gna Sa-ba-di-ni Kath-ryn Ker-n-i-ghan Krom-mes Lar-ra-bee
  Pat-rick Port-able Post-Script Pren-tice Rich-ard Richt-er Ro-bert Sha-mos
  Spring-er The-o-dore Uz-ga-lis }


\bibliographystyle{abbrv}
\bibliography{journal}

\end{document}
